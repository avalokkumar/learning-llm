{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 21: Prompt Engineering Patterns - Part 3\n",
    "\n",
    "In this notebook, we'll implement function calling, a powerful technique that allows language models to interact with external tools and APIs.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We'll cover:\n",
    "1. Setting up the environment\n",
    "2. Defining a function with a JSON schema\n",
    "3. Implementing a function calling loop\n",
    "4. Testing the function calling implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting Up the Environment\n",
    "\n",
    "First, let's install and import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install openai python-dotenv requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables (API keys)\n",
    "load_dotenv()\n",
    "\n",
    "# Set up OpenAI API\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Check if API key is available\n",
    "API_KEY_AVAILABLE = openai.api_key and openai.api_key != \"your-api-key-here\"\n",
    "print(f\"OpenAI API Key Available: {API_KEY_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defining a Function and its Schema\n",
    "\n",
    "We'll define a simple function to get the current weather and create a JSON schema to describe it to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location, unit=\"celsius\"):\n",
    "    \"\"\"Get the current weather in a given location.\"\"\"\n",
    "    # This is a mock function for demonstration purposes\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"22\", \"unit\": \"celsius\"})\n",
    "\n",
    "# Define the JSON schema for the function\n",
    "weather_function_schema = {\n",
    "    \"name\": \"get_current_weather\",\n",
    "    \"description\": \"Get the current weather in a given location\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city and state, e.g., San Francisco, CA\"\n",
    "            },\n",
    "            \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]}\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementing the Function Calling Loop\n",
    "\n",
    "Now, let's create a function that handles the interaction with the model, including executing the function call if the model requests it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation(user_prompt):\n",
    "    \"\"\"Run a conversation with the model, handling function calls.\"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    tools = [weather_function_schema] # In newer OpenAI versions, this is `tools`\n",
    "    \n",
    "    if not API_KEY_AVAILABLE:\n",
    "        print(\"API key not available. Simulating function call.\")\n",
    "        return f\"Simulated response: The weather in London is 15 degrees Celsius.\"\n",
    "\n",
    "    # First API call to see if a function needs to be called\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\", # Use a model that supports function calling\n",
    "        messages=messages,\n",
    "        functions=tools, # In newer versions, this is `tools`\n",
    "        function_call=\"auto\",  # Let the model decide\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "    # Check if the model wants to call a function\n",
    "    if response_message.get(\"function_call\"):\n",
    "        available_functions = {\n",
    "            \"get_current_weather\": get_current_weather,\n",
    "        }\n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        \n",
    "        # Call the function\n",
    "        function_response = function_to_call(\n",
    "            location=function_args.get(\"location\"),\n",
    "            unit=function_args.get(\"unit\")\n",
    "        )\n",
    "\n",
    "        # Send the function response back to the model\n",
    "        messages.append(response_message)  # Add the assistant's turn\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  # Add the function's response\n",
    "        \n",
    "        # Second API call to get the final response\n",
    "        second_response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0613\",\n",
    "            messages=messages,\n",
    "        )\n",
    "        return second_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        return response_message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing the Function Calling Implementation\n",
    "\n",
    "Let's test our function calling implementation with a few different prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prompts\n",
    "test_prompts = [\n",
    "    \"What's the weather like in San Francisco?\",\n",
    "    \"What's the weather in Tokyo in celsius?\",\n",
    "    \"Tell me a fun fact about the sun.\" # This should not trigger a function call\n",
    "]\n",
    "\n",
    "# Run the tests\n",
    "for prompt in test_prompts:\n",
    "    print(f\"User Prompt: {prompt}\")\n",
    "    final_response = run_conversation(prompt)\n",
    "    print(f\"Final Response: {final_response}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "In this notebook, we've implemented a basic function calling system. Here are the key takeaways:\n",
    "\n",
    "1. **JSON Schemas**: We define our functions using JSON schemas to make them understandable to the model.\n",
    "2. **Two-Step Process**: Function calling is typically a two-step process: the model first indicates its intent to call a function, and after the function is executed, the result is sent back to the model to generate a final response.\n",
    "3. **Tool Integration**: This capability allows language models to interact with the real world, access external data, and perform actions, significantly expanding their usefulness.\n",
    "\n",
    "This concludes our exploration of prompt engineering for Day 21. We've covered fundamental and advanced techniques, from zero-shot prompting to function calling, that are essential for building robust and effective language model applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
