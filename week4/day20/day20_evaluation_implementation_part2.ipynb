{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 20: Evaluation Suites for Language Models - Part 2\n",
    "\n",
    "In this notebook, we'll focus on measuring and reducing hallucinations in language models, which is a critical aspect of model evaluation.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Hallucinations in language models refer to generated content that is factually incorrect, internally inconsistent, or not supported by the provided context or real-world knowledge. Detecting and mitigating hallucinations is essential for building reliable AI systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Types of Hallucinations\n",
    "\n",
    "Hallucinations can be categorized into several types:\n",
    "\n",
    "1. **Factual Hallucinations**: Generating content that contradicts established facts\n",
    "2. **Contextual Hallucinations**: Generating content not supported by the provided context\n",
    "3. **Logical Hallucinations**: Generating content with internal contradictions or logical inconsistencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementing a Hallucination Detector\n",
    "\n",
    "Let's implement a simple hallucination detector that can identify potential hallucinations in model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HallucinationDetector:\n",
    "    \"\"\"A simple detector for identifying potential hallucinations in text.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Define patterns that often indicate hallucinations\n",
    "        self.uncertainty_phrases = [\n",
    "            \"i believe\", \"i think\", \"probably\", \"likely\", \"might be\", \"could be\",\n",
    "            \"possibly\", \"perhaps\", \"may have\", \"may be\", \"seems to be\"\n",
    "        ]\n",
    "        \n",
    "        self.factual_claim_patterns = [\n",
    "            \"in fact\", \"actually\", \"definitely\", \"certainly\", \"undoubtedly\",\n",
    "            \"always\", \"never\", \"everyone knows\", \"it is well known\", \"clearly\"\n",
    "        ]\n",
    "        \n",
    "        self.contradiction_indicators = [\n",
    "            \"however\", \"but\", \"although\", \"nevertheless\", \"conversely\",\n",
    "            \"on the other hand\", \"in contrast\", \"yet\", \"instead\", \"rather\"\n",
    "        ]\n",
    "        \n",
    "        # Knowledge base for fact-checking (very limited for demonstration)\n",
    "        self.knowledge_base = {\n",
    "            \"earth\": {\"shape\": \"oblate spheroid\", \"satellite\": \"moon\", \"star\": \"sun\"},\n",
    "            \"water\": {\"boiling point\": \"100째C\", \"freezing point\": \"0째C\", \"molecule\": \"H2O\"},\n",
    "            \"human body\": {\"bones\": \"206\", \"blood type\": \"A, B, AB, O\", \"brain\": \"cerebrum, cerebellum, brainstem\"},\n",
    "            \"python\": {\"creator\": \"Guido van Rossum\", \"first release\": \"1991\", \"type\": \"programming language\"},\n",
    "            \"shakespeare\": {\"born\": \"1564\", \"died\": \"1616\", \"works\": \"hamlet, macbeth, romeo and juliet\"}\n",
    "        }\n",
    "    \n",
    "    def check_uncertainty(self, text):\n",
    "        \"\"\"Check if text contains uncertainty phrases.\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        found_phrases = [phrase for phrase in self.uncertainty_phrases if phrase in text_lower]\n",
    "        return len(found_phrases) > 0, found_phrases\n",
    "    \n",
    "    def check_strong_claims(self, text):\n",
    "        \"\"\"Check if text contains strong factual claims.\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        found_phrases = [phrase for phrase in self.factual_claim_patterns if phrase in text_lower]\n",
    "        return len(found_phrases) > 0, found_phrases\n",
    "    \n",
    "    def check_contradictions(self, text):\n",
    "        \"\"\"Check for potential contradictions in text.\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        found_phrases = [phrase for phrase in self.contradiction_indicators if phrase in text_lower]\n",
    "        return len(found_phrases) > 0, found_phrases\n",
    "    \n",
    "    def check_against_knowledge_base(self, text):\n",
    "        \"\"\"Check text against knowledge base for factual accuracy.\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        potential_errors = []\n",
    "        \n",
    "        # Very simple fact checking (for demonstration only)\n",
    "        for topic, facts in self.knowledge_base.items():\n",
    "            if topic in text_lower:\n",
    "                for attribute, value in facts.items():\n",
    "                    # Check if attribute is mentioned\n",
    "                    if attribute in text_lower:\n",
    "                        # Check if the correct value is mentioned\n",
    "                        if value not in text_lower:\n",
    "                            # Look for incorrect values\n",
    "                            words_after_attribute = text_lower.split(attribute)[1].split()[:5]\n",
    "                            potential_errors.append(f\"Potential error about {topic}'s {attribute}: expected '{value}'\")\n",
    "        \n",
    "        return len(potential_errors) > 0, potential_errors\n",
    "    \n",
    "    def detect_hallucinations(self, text):\n",
    "        \"\"\"Detect potential hallucinations in text.\"\"\"\n",
    "        results = {\n",
    "            \"has_uncertainty\": False,\n",
    "            \"uncertainty_phrases\": [],\n",
    "            \"has_strong_claims\": False,\n",
    "            \"strong_claim_phrases\": [],\n",
    "            \"has_contradictions\": False,\n",
    "            \"contradiction_phrases\": [],\n",
    "            \"has_factual_errors\": False,\n",
    "            \"potential_factual_errors\": [],\n",
    "            \"hallucination_score\": 0.0,\n",
    "            \"hallucination_risk\": \"low\"\n",
    "        }\n",
    "        \n",
    "        # Check for uncertainty\n",
    "        results[\"has_uncertainty\"], results[\"uncertainty_phrases\"] = self.check_uncertainty(text)\n",
    "        \n",
    "        # Check for strong claims\n",
    "        results[\"has_strong_claims\"], results[\"strong_claim_phrases\"] = self.check_strong_claims(text)\n",
    "        \n",
    "        # Check for contradictions\n",
    "        results[\"has_contradictions\"], results[\"contradiction_phrases\"] = self.check_contradictions(text)\n",
    "        \n",
    "        # Check against knowledge base\n",
    "        results[\"has_factual_errors\"], results[\"potential_factual_errors\"] = self.check_against_knowledge_base(text)\n",
    "        \n",
    "        # Calculate hallucination score (simple heuristic)\n",
    "        score = 0.0\n",
    "        if results[\"has_uncertainty\"]:\n",
    "            score += 0.2 * len(results[\"uncertainty_phrases\"])\n",
    "        if results[\"has_strong_claims\"]:\n",
    "            score += 0.3 * len(results[\"strong_claim_phrases\"])\n",
    "        if results[\"has_contradictions\"]:\n",
    "            score += 0.4 * len(results[\"contradiction_phrases\"])\n",
    "        if results[\"has_factual_errors\"]:\n",
    "            score += 0.5 * len(results[\"potential_factual_errors\"])\n",
    "        \n",
    "        results[\"hallucination_score\"] = min(1.0, score)  # Cap at 1.0\n",
    "        \n",
    "        # Determine risk level\n",
    "        if results[\"hallucination_score\"] < 0.3:\n",
    "            results[\"hallucination_risk\"] = \"low\"\n",
    "        elif results[\"hallucination_score\"] < 0.6:\n",
    "            results[\"hallucination_risk\"] = \"medium\"\n",
    "        else:\n",
    "            results[\"hallucination_risk\"] = \"high\"\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing the Hallucination Detector\n",
    "\n",
    "Let's test our hallucination detector on some example texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hallucination detector\n",
    "detector = HallucinationDetector()\n",
    "\n",
    "# Test texts with varying levels of potential hallucination\n",
    "test_texts = [\n",
    "    \"The Earth is an oblate spheroid and orbits around the Sun. It has one natural satellite, the Moon.\",\n",
    "    \"I believe the Earth might be flat, although scientists claim it's round. In fact, many people throughout history have believed the Earth is flat.\",\n",
    "    \"Water boils at 100째C at sea level, but it actually boils at 90째C on mountains. However, it might boil at different temperatures depending on altitude.\",\n",
    "    \"Shakespeare was born in 1564 and died in 1616. He definitely wrote 154 sonnets and 37 plays, including Hamlet, Macbeth, and Romeo and Juliet.\",\n",
    "    \"Python was created by Guido van Rossum in 1991. It's certainly the most popular programming language ever created, and everyone knows it's the easiest to learn.\"\n",
    "]\n",
    "\n",
    "# Test the detector\n",
    "for i, text in enumerate(test_texts):\n",
    "    print(f\"\\nText {i+1}:\\n{text}\\n\")\n",
    "    results = detector.detect_hallucinations(text)\n",
    "    print(f\"Hallucination Risk: {results['hallucination_risk']} (Score: {results['hallucination_score']:.2f})\")\n",
    "    \n",
    "    if results[\"has_uncertainty\"]:\n",
    "        print(f\"Uncertainty Phrases: {', '.join(results['uncertainty_phrases'])}\")\n",
    "    \n",
    "    if results[\"has_strong_claims\"]:\n",
    "        print(f\"Strong Claims: {', '.join(results['strong_claim_phrases'])}\")\n",
    "    \n",
    "    if results[\"has_contradictions\"]:\n",
    "        print(f\"Potential Contradictions: {', '.join(results['contradiction_phrases'])}\")\n",
    "    \n",
    "    if results[\"has_factual_errors\"]:\n",
    "        print(f\"Potential Factual Errors: {', '.join(results['potential_factual_errors'])}\")\n",
    "    \n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementing a Retrieval-Augmented Generation (RAG) System\n",
    "\n",
    "One effective way to reduce hallucinations is through Retrieval-Augmented Generation (RAG), which grounds model responses in retrieved information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRAG:\n",
    "    \"\"\"A simple Retrieval-Augmented Generation system.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, tokenizer, knowledge_base):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.knowledge_base = knowledge_base\n",
    "    \n",
    "    def retrieve_relevant_info(self, query):\n",
    "        \"\"\"Retrieve relevant information from knowledge base.\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        relevant_info = []\n",
    "        \n",
    "        # Simple keyword matching (in a real system, this would use embeddings or BM25)\n",
    "        for topic, facts in self.knowledge_base.items():\n",
    "            if topic in query_lower:\n",
    "                topic_info = f\"{topic.capitalize()}: \"\n",
    "                fact_strings = [f\"{attr} is {val}\" for attr, val in facts.items()]\n",
    "                topic_info += \", \".join(fact_strings)\n",
    "                relevant_info.append(topic_info)\n",
    "        \n",
    "        return \"\\n\".join(relevant_info) if relevant_info else \"\"\n",
    "    \n",
    "    def generate_response(self, query, max_new_tokens=100):\n",
    "        \"\"\"Generate a response using RAG.\"\"\"\n",
    "        # Retrieve relevant information\n",
    "        retrieved_info = self.retrieve_relevant_info(query)\n",
    "        \n",
    "        # Create augmented prompt\n",
    "        if retrieved_info:\n",
    "            augmented_prompt = f\"\"\"Based on the following information:\\n\\n{retrieved_info}\\n\\nPlease answer: {query}\"\"\"\n",
    "        else:\n",
    "            augmented_prompt = f\"Please answer: {query}\"\n",
    "        \n",
    "        # Generate response\n",
    "        inputs = self.tokenizer(augmented_prompt, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                inputs[\"input_ids\"],\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9,\n",
    "                pad_token_id=self.tokenizer.pad_token_id\n",
    "            )\n",
    "        \n",
    "        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        response = response[len(self.tokenizer.decode(inputs[\"input_ids\"][0], skip_special_tokens=True)):].strip()\n",
    "        \n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"retrieved_info\": retrieved_info,\n",
    "            \"augmented_prompt\": augmented_prompt,\n",
    "            \"response\": response\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testing the RAG System\n",
    "\n",
    "Let's test our RAG system and compare it with standard generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model for demonstration\n",
    "try:\n",
    "    model_name = \"gpt2\"  # Using a small model for demonstration\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "    \n",
    "    # Add padding token if it doesn't exist\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "    \n",
    "    print(f\"Model loaded: {model_name}\")\n",
    "    \n",
    "    # Create RAG system\n",
    "    rag = SimpleRAG(model, tokenizer, detector.knowledge_base)\n",
    "    \n",
    "    # Test queries\n",
    "    test_queries = [\n",
    "        \"What shape is the Earth?\",\n",
    "        \"Tell me about water's boiling and freezing points.\",\n",
    "        \"When was Shakespeare born and what are some of his works?\",\n",
    "        \"Who created Python and when?\"\n",
    "    ]\n",
    "    \n",
    "    # Standard generation function\n",
    "    def standard_generate(query, max_new_tokens=100):\n",
    "        inputs = tokenizer(f\"Please answer: {query}\", return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                inputs[\"input_ids\"],\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9,\n",
    "                pad_token_id=tokenizer.pad_token_id\n",
    "            )\n",
    "        \n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        response = response[len(tokenizer.decode(inputs[\"input_ids\"][0], skip_special_tokens=True)):].strip()\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    # Compare standard generation vs. RAG\n",
    "    for query in test_queries:\n",
    "        print(f\"\\nQuery: {query}\\n\")\n",
    "        \n",
    "        # Standard generation\n",
    "        std_response = standard_generate(query)\n",
    "        print(f\"Standard Response:\\n{std_response}\\n\")\n",
    "        std_results = detector.detect_hallucinations(std_response)\n",
    "        print(f\"Hallucination Risk: {std_results['hallucination_risk']} (Score: {std_results['hallucination_score']:.2f})\\n\")\n",
    "        \n",
    "        # RAG generation\n",
    "        rag_result = rag.generate_response(query)\n",
    "        print(f\"Retrieved Info: {rag_result['retrieved_info']}\\n\")\n",
    "        print(f\"RAG Response:\\n{rag_result['response']}\\n\")\n",
    "        rag_results = detector.detect_hallucinations(rag_result['response'])\n",
    "        print(f\"Hallucination Risk: {rag_results['hallucination_risk']} (Score: {rag_results['hallucination_score']:.2f})\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error running RAG comparison: {e}\")\n",
    "    print(\"Skipping RAG demonstration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "In this notebook, we've explored techniques for measuring and reducing hallucinations in language models:\n",
    "\n",
    "1. We implemented a simple hallucination detector that can identify potential issues in model outputs\n",
    "2. We created a basic Retrieval-Augmented Generation (RAG) system to ground model responses in factual information\n",
    "3. We compared standard generation with RAG to demonstrate how retrieval can reduce hallucinations\n",
    "\n",
    "These techniques form an important part of a comprehensive evaluation framework for language models. By systematically measuring and addressing hallucinations, we can build more reliable and trustworthy AI systems.\n",
    "\n",
    "In practice, more sophisticated approaches would be used, including:\n",
    "\n",
    "- Advanced retrieval methods using dense embeddings or hybrid search\n",
    "- More comprehensive knowledge bases or external APIs\n",
    "- LLM-based evaluators for more nuanced hallucination detection\n",
    "- Self-consistency techniques that generate multiple responses and check for agreement\n",
    "\n",
    "The key takeaway is that hallucination detection and mitigation should be an integral part of any language model evaluation suite."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
