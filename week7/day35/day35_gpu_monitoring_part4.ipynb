{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 35: GPU Monitoring for LLM Services - Part 4\n",
    "\n",
    "Implementing comprehensive GPU monitoring for LLM services to track performance, utilization, and health.\n",
    "\n",
    "## Overview\n",
    "1. Setting up GPU monitoring with `pynvml`\n",
    "2. Key GPU metrics for LLMs\n",
    "3. GPU monitoring dashboard\n",
    "4. Alerting on GPU metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q pynvml matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pynvml import *\n",
    "from collections import defaultdict, deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting Up GPU Monitoring\n",
    "\n",
    "Initialize `pynvml` to access GPU metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPUMonitor:\n",
    "    \"\"\"GPU monitoring using pynvml.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.is_initialized = False\n",
    "        try:\n",
    "            nvmlInit()\n",
    "            self.device_count = nvmlDeviceGetCount()\n",
    "            self.handles = [nvmlDeviceGetHandleByIndex(i) for i in range(self.device_count)]\n",
    "            self.is_initialized = True\n",
    "            print(f\"NVML initialized. Found {self.device_count} GPUs.\")\n",
    "        except NVMLError as error:\n",
    "            print(f\"Failed to initialize NVML: {error}\")\n",
    "            print(\"GPU monitoring will be mocked.\")\n",
    "    \n",
    "    def get_gpu_metrics(self) -> dict:\n",
    "        \"\"\"Get key GPU metrics.\"\"\"\n",
    "        if not self.is_initialized:\n",
    "            return self._get_mock_metrics()\n",
    "        \n",
    "        metrics = {}\n",
    "        for i, handle in enumerate(self.handles):\n",
    "            utilization = nvmlDeviceGetUtilizationRates(handle)\n",
    "            memory = nvmlDeviceGetMemoryInfo(handle)\n",
    "            temperature = nvmlDeviceGetTemperature(handle, NVML_TEMPERATURE_GPU)\n",
    "            power = nvmlDeviceGetPowerUsage(handle) / 1000.0  # Watts\n",
    "            \n",
    "            metrics[f'gpu_{i}'] = {\n",
    "                'utilization_gpu': utilization.gpu,\n",
    "                'utilization_memory': utilization.memory,\n",
    "                'memory_total': memory.total,\n",
    "                'memory_used': memory.used,\n",
    "                'memory_free': memory.free,\n",
    "                'temperature': temperature,\n",
    "                'power_usage': power\n",
    "            }\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def _get_mock_metrics(self) -> dict:\n",
    "        \"\"\"Generate mock GPU metrics.\"\"\"\n",
    "        return {\n",
    "            'gpu_0': {\n",
    "                'utilization_gpu': np.random.uniform(60, 95),\n",
    "                'utilization_memory': np.random.uniform(50, 80),\n",
    "                'memory_total': 16e9,\n",
    "                'memory_used': np.random.uniform(8e9, 14e9),\n",
    "                'memory_free': 16e9 - np.random.uniform(8e9, 14e9),\n",
    "                'temperature': np.random.uniform(65, 85),\n",
    "                'power_usage': np.random.uniform(150, 250)\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def shutdown(self):\n",
    "        \"\"\"Shutdown NVML.\"\"\"\n",
    "        if self.is_initialized:\n",
    "            nvmlShutdown()\n",
    "            print(\"NVML shut down\")\n",
    "\n",
    "# Initialize GPU monitor\n",
    "gpu_monitor = GPUMonitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GPU Metrics Collector\n",
    "\n",
    "Collect GPU metrics over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPUMetricsCollector:\n",
    "    \"\"\"Collect GPU metrics over time.\"\"\"\n",
    "    \n",
    "    def __init__(self, monitor: GPUMonitor, interval=5):\n",
    "        self.monitor = monitor\n",
    "        self.interval = interval\n",
    "        self.history = defaultdict(lambda: deque(maxlen=100))\n",
    "        self.running = False\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"Start collecting metrics in the background.\"\"\"\n",
    "        self.running = True\n",
    "        self.thread = threading.Thread(target=self._collect, daemon=True)\n",
    "        self.thread.start()\n",
    "        print(\"GPU metrics collector started\")\n",
    "    \n",
    "    def stop(self):\n",
    "        \"\"\"Stop collecting metrics.\"\"\"\n",
    "        self.running = False\n",
    "        if hasattr(self, 'thread'):\n",
    "            self.thread.join()\n",
    "        print(\"GPU metrics collector stopped\")\n",
    "    \n",
    "    def _collect(self):\n",
    "        \"\"\"Background metrics collection loop.\"\"\"\n",
    "        while self.running:\n",
    "            metrics = self.monitor.get_gpu_metrics()\n",
    "            timestamp = time.time()\n",
    "            \n",
    "            for gpu_id, data in metrics.items():\n",
    "                for key, value in data.items():\n",
    "                    self.history[f'{gpu_id}_{key}'].append((timestamp, value))\n",
    "            \n",
    "            time.sleep(self.interval)\n",
    "    \n",
    "    def get_history(self) -> dict:\n",
    "        \"\"\"Get historical metrics.\"\"\"\n",
    "        return self.history\n",
    "\n",
    "# Initialize and start collector\n",
    "collector = GPUMetricsCollector(gpu_monitor, interval=1)\n",
    "collector.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GPU Monitoring Dashboard\n",
    "\n",
    "Create a simple dashboard to visualize GPU metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gpu_dashboard(history: dict):\n",
    "    \"\"\"Create a GPU monitoring dashboard.\"\"\"\n",
    "    \n",
    "    if not history:\n",
    "        print(\"No GPU metrics to display\")\n",
    "        return\n",
    "    \n",
    "    # Get GPU 0 data\n",
    "    gpu_id = 'gpu_0'\n",
    "    \n",
    "    # Extract data for plotting\n",
    "    util_gpu_data = history.get(f'{gpu_id}_utilization_gpu', [])\n",
    "    util_mem_data = history.get(f'{gpu_id}_utilization_memory', [])\n",
    "    mem_used_data = history.get(f'{gpu_id}_memory_used', [])\n",
    "    temp_data = history.get(f'{gpu_id}_temperature', [])\n",
    "    power_data = history.get(f'{gpu_id}_power_usage', [])\n",
    "    \n",
    "    if not util_gpu_data:\n",
    "        print(\"No data for GPU 0\")\n",
    "        return\n",
    "    \n",
    "    # Timestamps\n",
    "    timestamps = [t for t, v in util_gpu_data]\n",
    "    \n",
    "    # Create dashboard\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # GPU and Memory Utilization\n",
    "    ax1.plot(timestamps, [v for t, v in util_gpu_data], label='GPU Utilization')\n",
    "    ax1.plot(timestamps, [v for t, v in util_mem_data], label='Memory Utilization')\n",
    "    ax1.set_title('GPU and Memory Utilization')\n",
    "    ax1.set_ylabel('Utilization (%)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Memory Usage\n",
    "    ax2.plot(timestamps, [v / 1e9 for t, v in mem_used_data], label='Memory Used (GB)')\n",
    "    ax2.set_title('GPU Memory Usage')\n",
    "    ax2.set_ylabel('Memory (GB)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Temperature\n",
    "    ax3.plot(timestamps, [v for t, v in temp_data], label='Temperature', color='red')\n",
    "    ax3.axhline(y=85, color='r', linestyle='--', alpha=0.7, label='Critical Threshold')\n",
    "    ax3.set_title('GPU Temperature')\n",
    "    ax3.set_ylabel('Temperature (Â°C)')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Power Usage\n",
    "    ax4.plot(timestamps, [v for t, v in power_data], label='Power Usage', color='purple')\n",
    "    ax4.set_title('GPU Power Usage')\n",
    "    ax4.set_ylabel('Power (W)')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Simulate some activity and create dashboard\n",
    "print(\"Collecting GPU metrics for 10 seconds...\")\n",
    "time.sleep(10)\n",
    "collector.stop()\n",
    "\n",
    "# Create dashboard\n",
    "create_gpu_dashboard(collector.get_history())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Alerting on GPU Metrics\n",
    "\n",
    "Create a simple alerting system for GPU metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPUAlerter:\n",
    "    \"\"\"Simple alerting system for GPU metrics.\"\"\"\n",
    "    \n",
    "    def __init__(self, thresholds: dict):\n",
    "        self.thresholds = thresholds\n",
    "        self.alerts = []\n",
    "    \n",
    "    def check_alerts(self, metrics: dict):\n",
    "        \"\"\"Check metrics against thresholds.\"\"\"\n",
    "        self.alerts.clear()\n",
    "        \n",
    "        for gpu_id, data in metrics.items():\n",
    "            # Temperature alert\n",
    "            if data['temperature'] > self.thresholds.get('max_temp', 85):\n",
    "                self.alerts.append({\n",
    "                    'gpu_id': gpu_id,\n",
    "                    'metric': 'temperature',\n",
    "                    'value': data['temperature'],\n",
    "                    'threshold': self.thresholds['max_temp'],\n",
    "                    'severity': 'critical'\n",
    "                })\n",
    "            \n",
    "            # Memory usage alert\n",
    "            mem_usage_percent = (data['memory_used'] / data['memory_total']) * 100\n",
    "            if mem_usage_percent > self.thresholds.get('max_mem_percent', 90):\n",
    "                self.alerts.append({\n",
    "                    'gpu_id': gpu_id,\n",
    "                    'metric': 'memory_usage',\n",
    "                    'value': mem_usage_percent,\n",
    "                    'threshold': self.thresholds['max_mem_percent'],\n",
    "                    'severity': 'warning'\n",
    "                })\n",
    "            \n",
    "            # GPU underutilization alert\n",
    "            if data['utilization_gpu'] < self.thresholds.get('min_gpu_util', 10):\n",
    "                self.alerts.append({\n",
    "                    'gpu_id': gpu_id,\n",
    "                    'metric': 'gpu_utilization',\n",
    "                    'value': data['utilization_gpu'],\n",
    "                    'threshold': self.thresholds['min_gpu_util'],\n",
    "                    'severity': 'info'\n",
    "                })\n",
    "        \n",
    "        return self.alerts\n",
    "\n",
    "# Define alert thresholds\n",
    "alert_thresholds = {\n",
    "    'max_temp': 80,          # 80Â°C\n",
    "    'max_mem_percent': 90, # 90%\n",
    "    'min_gpu_util': 10       # 10%\n",
    "}\n",
    "\n",
    "# Initialize alerter\n",
    "alerter = GPUAlerter(alert_thresholds)\n",
    "\n",
    "# Check for alerts\n",
    "current_metrics = gpu_monitor.get_gpu_metrics()\n",
    "alerts = alerter.check_alerts(current_metrics)\n",
    "\n",
    "print(\"\\n=== GPU Alerts ===\")\n",
    "if alerts:\n",
    "    for alert in alerts:\n",
    "        print(f\"[{alert['severity'].upper()}] {alert['gpu_id']}: {alert['metric']} is {alert['value']:.1f}, \"\n",
    "              f\"threshold is {alert['threshold']}\")\n",
    "else:\n",
    "    print(\"No active alerts. System is healthy.\")\n",
    "\n",
    "# Shutdown monitor\n",
    "gpu_monitor.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "GPU monitoring is crucial for LLM services:\n",
    "\n",
    "1. **Performance Bottlenecks**: Identify underutilized GPUs or memory bottlenecks\n",
    "2. **Hardware Health**: Monitor temperature and power to prevent damage\n",
    "3. **Resource Optimization**: Ensure efficient use of expensive GPU resources\n",
    "4. **Capacity Planning**: Understand usage patterns to plan for future needs\n",
    "\n",
    "**Key Metrics**:\n",
    "- GPU and memory utilization\n",
    "- Memory usage (total, used, free)\n",
    "- Temperature and power consumption\n",
    "- Error counts and throttling events\n",
    "\n",
    "Next, we'll integrate all observability components into a cohesive telemetry system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
