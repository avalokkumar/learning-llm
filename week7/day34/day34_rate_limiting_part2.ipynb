{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 34: Rate Limiting Strategies - Part 2\n",
    "\n",
    "Implementing rate limiting algorithms to control resource usage and ensure fair access in LLM serving systems.\n",
    "\n",
    "## Overview\n",
    "1. Token bucket algorithm\n",
    "2. Sliding window rate limiter\n",
    "3. Multi-dimensional rate limiting\n",
    "4. Fair queuing implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque, defaultdict\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Token Bucket Rate Limiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenBucket:\n",
    "    def __init__(self, capacity, refill_rate):\n",
    "        \"\"\"\n",
    "        Token bucket rate limiter.\n",
    "        \n",
    "        Args:\n",
    "            capacity: Maximum number of tokens\n",
    "            refill_rate: Tokens added per second\n",
    "        \"\"\"\n",
    "        self.capacity = capacity\n",
    "        self.tokens = capacity\n",
    "        self.refill_rate = refill_rate\n",
    "        self.last_refill = time.time()\n",
    "        self.lock = threading.Lock()\n",
    "    \n",
    "    def _refill(self):\n",
    "        \"\"\"Refill tokens based on elapsed time.\"\"\"\n",
    "        now = time.time()\n",
    "        elapsed = now - self.last_refill\n",
    "        tokens_to_add = elapsed * self.refill_rate\n",
    "        \n",
    "        self.tokens = min(self.capacity, self.tokens + tokens_to_add)\n",
    "        self.last_refill = now\n",
    "    \n",
    "    def consume(self, tokens=1):\n",
    "        \"\"\"Try to consume tokens. Returns True if successful.\"\"\"\n",
    "        with self.lock:\n",
    "            self._refill()\n",
    "            \n",
    "            if self.tokens >= tokens:\n",
    "                self.tokens -= tokens\n",
    "                return True\n",
    "            return False\n",
    "    \n",
    "    def get_tokens(self):\n",
    "        \"\"\"Get current token count.\"\"\"\n",
    "        with self.lock:\n",
    "            self._refill()\n",
    "            return self.tokens\n",
    "\n",
    "# Test token bucket\n",
    "bucket = TokenBucket(capacity=10, refill_rate=2)  # 10 tokens max, 2 per second\n",
    "\n",
    "print(\"Testing Token Bucket:\")\n",
    "print(f\"Initial tokens: {bucket.get_tokens():.1f}\")\n",
    "\n",
    "# Consume tokens quickly\n",
    "for i in range(15):\n",
    "    success = bucket.consume(1)\n",
    "    print(f\"Request {i+1}: {'✓' if success else '✗'} (tokens: {bucket.get_tokens():.1f})\")\n",
    "    time.sleep(0.1)\n",
    "\n",
    "print(f\"\\nAfter 1.5 seconds: {bucket.get_tokens():.1f} tokens\")\n",
    "time.sleep(1.5)\n",
    "print(f\"After refill: {bucket.get_tokens():.1f} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sliding Window Rate Limiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindowRateLimiter:\n",
    "    def __init__(self, max_requests, window_size_seconds):\n",
    "        \"\"\"\n",
    "        Sliding window rate limiter.\n",
    "        \n",
    "        Args:\n",
    "            max_requests: Maximum requests in window\n",
    "            window_size_seconds: Window size in seconds\n",
    "        \"\"\"\n",
    "        self.max_requests = max_requests\n",
    "        self.window_size = window_size_seconds\n",
    "        self.requests = deque()\n",
    "        self.lock = threading.Lock()\n",
    "    \n",
    "    def _cleanup_old_requests(self):\n",
    "        \"\"\"Remove requests outside the current window.\"\"\"\n",
    "        now = time.time()\n",
    "        cutoff = now - self.window_size\n",
    "        \n",
    "        while self.requests and self.requests[0] < cutoff:\n",
    "            self.requests.popleft()\n",
    "    \n",
    "    def is_allowed(self):\n",
    "        \"\"\"Check if request is allowed.\"\"\"\n",
    "        with self.lock:\n",
    "            self._cleanup_old_requests()\n",
    "            \n",
    "            if len(self.requests) < self.max_requests:\n",
    "                self.requests.append(time.time())\n",
    "                return True\n",
    "            return False\n",
    "    \n",
    "    def get_current_count(self):\n",
    "        \"\"\"Get current request count in window.\"\"\"\n",
    "        with self.lock:\n",
    "            self._cleanup_old_requests()\n",
    "            return len(self.requests)\n",
    "\n",
    "# Test sliding window\n",
    "limiter = SlidingWindowRateLimiter(max_requests=5, window_size_seconds=2)\n",
    "\n",
    "print(\"\\nTesting Sliding Window Rate Limiter:\")\n",
    "print(\"Limit: 5 requests per 2 seconds\")\n",
    "\n",
    "for i in range(10):\n",
    "    allowed = limiter.is_allowed()\n",
    "    count = limiter.get_current_count()\n",
    "    print(f\"Request {i+1}: {'✓' if allowed else '✗'} (count: {count}/5)\")\n",
    "    time.sleep(0.3)\n",
    "\n",
    "print(f\"\\nAfter window expires: {limiter.get_current_count()}/5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-Dimensional Rate Limiter for LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMRateLimiter:\n",
    "    def __init__(self, limits):\n",
    "        \"\"\"\n",
    "        Multi-dimensional rate limiter for LLM services.\n",
    "        \n",
    "        Args:\n",
    "            limits: Dict with limit configurations\n",
    "                   e.g., {\n",
    "                       'requests_per_minute': 60,\n",
    "                       'tokens_per_minute': 10000,\n",
    "                       'cost_per_hour': 10.0\n",
    "                   }\n",
    "        \"\"\"\n",
    "        self.limits = limits\n",
    "        self.counters = defaultdict(lambda: deque())\n",
    "        self.lock = threading.Lock()\n",
    "    \n",
    "    def _cleanup_counter(self, counter_name, window_seconds):\n",
    "        \"\"\"Clean up old entries from a counter.\"\"\"\n",
    "        now = time.time()\n",
    "        cutoff = now - window_seconds\n",
    "        \n",
    "        counter = self.counters[counter_name]\n",
    "        while counter and counter[0]['timestamp'] < cutoff:\n",
    "            counter.popleft()\n",
    "    \n",
    "    def check_limits(self, request_tokens=0, estimated_cost=0):\n",
    "        \"\"\"Check if request is within all limits.\"\"\"\n",
    "        with self.lock:\n",
    "            now = time.time()\n",
    "            \n",
    "            # Check request rate limit\n",
    "            if 'requests_per_minute' in self.limits:\n",
    "                self._cleanup_counter('requests', 60)\n",
    "                if len(self.counters['requests']) >= self.limits['requests_per_minute']:\n",
    "                    return False, \"Request rate limit exceeded\"\n",
    "            \n",
    "            # Check token rate limit\n",
    "            if 'tokens_per_minute' in self.limits:\n",
    "                self._cleanup_counter('tokens', 60)\n",
    "                current_tokens = sum(entry['value'] for entry in self.counters['tokens'])\n",
    "                if current_tokens + request_tokens > self.limits['tokens_per_minute']:\n",
    "                    return False, \"Token rate limit exceeded\"\n",
    "            \n",
    "            # Check cost limit\n",
    "            if 'cost_per_hour' in self.limits:\n",
    "                self._cleanup_counter('cost', 3600)\n",
    "                current_cost = sum(entry['value'] for entry in self.counters['cost'])\n",
    "                if current_cost + estimated_cost > self.limits['cost_per_hour']:\n",
    "                    return False, \"Cost limit exceeded\"\n",
    "            \n",
    "            return True, \"OK\"\n",
    "    \n",
    "    def record_usage(self, tokens_used=0, actual_cost=0):\n",
    "        \"\"\"Record actual usage after request completion.\"\"\"\n",
    "        with self.lock:\n",
    "            now = time.time()\n",
    "            \n",
    "            # Record request\n",
    "            self.counters['requests'].append({\n",
    "                'timestamp': now,\n",
    "                'value': 1\n",
    "            })\n",
    "            \n",
    "            # Record tokens\n",
    "            if tokens_used > 0:\n",
    "                self.counters['tokens'].append({\n",
    "                    'timestamp': now,\n",
    "                    'value': tokens_used\n",
    "                })\n",
    "            \n",
    "            # Record cost\n",
    "            if actual_cost > 0:\n",
    "                self.counters['cost'].append({\n",
    "                    'timestamp': now,\n",
    "                    'value': actual_cost\n",
    "                })\n",
    "    \n",
    "    def get_usage_stats(self):\n",
    "        \"\"\"Get current usage statistics.\"\"\"\n",
    "        with self.lock:\n",
    "            # Clean up all counters\n",
    "            self._cleanup_counter('requests', 60)\n",
    "            self._cleanup_counter('tokens', 60)\n",
    "            self._cleanup_counter('cost', 3600)\n",
    "            \n",
    "            return {\n",
    "                'requests_last_minute': len(self.counters['requests']),\n",
    "                'tokens_last_minute': sum(entry['value'] for entry in self.counters['tokens']),\n",
    "                'cost_last_hour': sum(entry['value'] for entry in self.counters['cost'])\n",
    "            }\n",
    "\n",
    "# Test multi-dimensional rate limiter\n",
    "llm_limiter = LLMRateLimiter({\n",
    "    'requests_per_minute': 10,\n",
    "    'tokens_per_minute': 1000,\n",
    "    'cost_per_hour': 5.0\n",
    "})\n",
    "\n",
    "print(\"\\nTesting Multi-Dimensional Rate Limiter:\")\n",
    "print(\"Limits: 10 req/min, 1000 tokens/min, $5/hour\")\n",
    "\n",
    "# Simulate requests\n",
    "for i in range(15):\n",
    "    tokens = np.random.randint(50, 200)\n",
    "    cost = tokens * 0.001  # $0.001 per token\n",
    "    \n",
    "    allowed, reason = llm_limiter.check_limits(tokens, cost)\n",
    "    \n",
    "    if allowed:\n",
    "        llm_limiter.record_usage(tokens, cost)\n",
    "        print(f\"Request {i+1}: ✓ ({tokens} tokens, ${cost:.3f})\")\n",
    "    else:\n",
    "        print(f\"Request {i+1}: ✗ ({reason})\")\n",
    "    \n",
    "    time.sleep(0.1)\n",
    "\n",
    "# Show final stats\n",
    "stats = llm_limiter.get_usage_stats()\n",
    "print(f\"\\nFinal usage:\")\n",
    "print(f\"  Requests: {stats['requests_last_minute']}/10\")\n",
    "print(f\"  Tokens: {stats['tokens_last_minute']}/1000\")\n",
    "print(f\"  Cost: ${stats['cost_last_hour']:.3f}/$5.00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fair Queuing for Multi-Tenant Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairQueue:\n",
    "    def __init__(self, max_queue_size=100):\n",
    "        self.queues = defaultdict(lambda: deque())\n",
    "        self.weights = defaultdict(lambda: 1.0)  # Default weight\n",
    "        self.last_served = defaultdict(lambda: 0)\n",
    "        self.max_queue_size = max_queue_size\n",
    "        self.lock = threading.Lock()\n",
    "        self.request_counter = 0\n",
    "    \n",
    "    def set_weight(self, tenant_id, weight):\n",
    "        \"\"\"Set weight for a tenant (higher weight = more resources).\"\"\"\n",
    "        self.weights[tenant_id] = weight\n",
    "    \n",
    "    def enqueue(self, tenant_id, request):\n",
    "        \"\"\"Add request to tenant's queue.\"\"\"\n",
    "        with self.lock:\n",
    "            if len(self.queues[tenant_id]) >= self.max_queue_size:\n",
    "                return False, \"Queue full\"\n",
    "            \n",
    "            self.request_counter += 1\n",
    "            request['id'] = self.request_counter\n",
    "            request['enqueue_time'] = time.time()\n",
    "            \n",
    "            self.queues[tenant_id].append(request)\n",
    "            return True, \"Enqueued\"\n",
    "    \n",
    "    def dequeue(self):\n",
    "        \"\"\"Dequeue next request using weighted fair queuing.\"\"\"\n",
    "        with self.lock:\n",
    "            # Find tenant with highest priority (weight / last_served)\n",
    "            best_tenant = None\n",
    "            best_priority = -1\n",
    "            \n",
    "            for tenant_id, queue in self.queues.items():\n",
    "                if queue:  # Non-empty queue\n",
    "                    # Calculate priority (weight / (time since last served + 1))\n",
    "                    time_since_served = time.time() - self.last_served[tenant_id]\n",
    "                    priority = self.weights[tenant_id] / (time_since_served + 1)\n",
    "                    \n",
    "                    if priority > best_priority:\n",
    "                        best_priority = priority\n",
    "                        best_tenant = tenant_id\n",
    "            \n",
    "            if best_tenant:\n",
    "                request = self.queues[best_tenant].popleft()\n",
    "                self.last_served[best_tenant] = time.time()\n",
    "                \n",
    "                # Calculate wait time\n",
    "                request['wait_time'] = time.time() - request['enqueue_time']\n",
    "                request['tenant_id'] = best_tenant\n",
    "                \n",
    "                return request\n",
    "            \n",
    "            return None\n",
    "    \n",
    "    def get_queue_stats(self):\n",
    "        \"\"\"Get queue statistics.\"\"\"\n",
    "        with self.lock:\n",
    "            stats = {}\n",
    "            for tenant_id, queue in self.queues.items():\n",
    "                stats[tenant_id] = {\n",
    "                    'queue_length': len(queue),\n",
    "                    'weight': self.weights[tenant_id],\n",
    "                    'last_served': self.last_served[tenant_id]\n",
    "                }\n",
    "            return stats\n",
    "\n",
    "# Test fair queuing\n",
    "fair_queue = FairQueue()\n",
    "\n",
    "# Set different weights for tenants\n",
    "fair_queue.set_weight('premium', 3.0)    # Premium tenant gets 3x resources\n",
    "fair_queue.set_weight('standard', 1.0)   # Standard tenant\n",
    "fair_queue.set_weight('basic', 0.5)      # Basic tenant gets 0.5x resources\n",
    "\n",
    "print(\"\\nTesting Fair Queuing:\")\n",
    "print(\"Weights: Premium=3.0, Standard=1.0, Basic=0.5\")\n",
    "\n",
    "# Add requests from different tenants\n",
    "tenants = ['premium', 'standard', 'basic']\n",
    "for i in range(15):\n",
    "    tenant = tenants[i % 3]\n",
    "    request = {'data': f'Request {i+1} from {tenant}'}\n",
    "    \n",
    "    success, msg = fair_queue.enqueue(tenant, request)\n",
    "    if success:\n",
    "        print(f\"  Enqueued: {request['data']}\")\n",
    "\n",
    "# Process requests\n",
    "print(\"\\nProcessing requests (fair queuing):\")\n",
    "processed_count = defaultdict(int)\n",
    "total_wait_times = defaultdict(list)\n",
    "\n",
    "while True:\n",
    "    request = fair_queue.dequeue()\n",
    "    if not request:\n",
    "        break\n",
    "    \n",
    "    tenant = request['tenant_id']\n",
    "    processed_count[tenant] += 1\n",
    "    total_wait_times[tenant].append(request['wait_time'])\n",
    "    \n",
    "    print(f\"  Processed: {request['data']} (wait: {request['wait_time']:.3f}s)\")\n",
    "    time.sleep(0.1)  # Simulate processing time\n",
    "\n",
    "# Show fairness results\n",
    "print(\"\\nFairness Results:\")\n",
    "for tenant in tenants:\n",
    "    count = processed_count[tenant]\n",
    "    weight = fair_queue.weights[tenant]\n",
    "    avg_wait = np.mean(total_wait_times[tenant]) if total_wait_times[tenant] else 0\n",
    "    \n",
    "    print(f\"  {tenant.capitalize()}: {count} requests (weight: {weight}, avg wait: {avg_wait:.3f}s)\")\n",
    "\n",
    "# Calculate fairness ratio\n",
    "standard_count = processed_count['standard']\n",
    "if standard_count > 0:\n",
    "    premium_ratio = processed_count['premium'] / standard_count\n",
    "    basic_ratio = processed_count['basic'] / standard_count\n",
    "    \n",
    "    print(f\"\\nFairness Ratios (vs Standard):\")\n",
    "    print(f\"  Premium: {premium_ratio:.2f} (expected: 3.0)\")\n",
    "    print(f\"  Basic: {basic_ratio:.2f} (expected: 0.5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Rate Limiting Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_rate_limiting_scenarios():\n",
    "    \"\"\"Compare different rate limiting algorithms under load.\"\"\"\n",
    "    \n",
    "    # Test parameters\n",
    "    request_rates = [1, 2, 5, 10, 15, 20]  # requests per second\n",
    "    test_duration = 10  # seconds\n",
    "    \n",
    "    results = {\n",
    "        'token_bucket': [],\n",
    "        'sliding_window': [],\n",
    "        'no_limit': []\n",
    "    }\n",
    "    \n",
    "    for rate in request_rates:\n",
    "        print(f\"Testing at {rate} req/s...\")\n",
    "        \n",
    "        # Token bucket (10 capacity, 5 refill rate)\n",
    "        bucket = TokenBucket(capacity=10, refill_rate=5)\n",
    "        bucket_accepted = 0\n",
    "        \n",
    "        # Sliding window (50 requests per 10 seconds)\n",
    "        window = SlidingWindowRateLimiter(max_requests=50, window_size_seconds=10)\n",
    "        window_accepted = 0\n",
    "        \n",
    "        # No limit baseline\n",
    "        no_limit_accepted = 0\n",
    "        \n",
    "        # Simulate requests\n",
    "        start_time = time.time()\n",
    "        request_interval = 1.0 / rate\n",
    "        \n",
    "        while time.time() - start_time < test_duration:\n",
    "            # Token bucket test\n",
    "            if bucket.consume(1):\n",
    "                bucket_accepted += 1\n",
    "            \n",
    "            # Sliding window test\n",
    "            if window.is_allowed():\n",
    "                window_accepted += 1\n",
    "            \n",
    "            # No limit test\n",
    "            no_limit_accepted += 1\n",
    "            \n",
    "            time.sleep(request_interval)\n",
    "        \n",
    "        results['token_bucket'].append(bucket_accepted / test_duration)\n",
    "        results['sliding_window'].append(window_accepted / test_duration)\n",
    "        results['no_limit'].append(no_limit_accepted / test_duration)\n",
    "    \n",
    "    return request_rates, results\n",
    "\n",
    "# Run performance comparison\n",
    "print(\"Running rate limiting performance analysis...\")\n",
    "rates, results = simulate_rate_limiting_scenarios()\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(rates, results['no_limit'], 'k--', label='No Limit', alpha=0.7)\n",
    "plt.plot(rates, results['token_bucket'], 'o-', label='Token Bucket (10 cap, 5/s refill)')\n",
    "plt.plot(rates, results['sliding_window'], 's-', label='Sliding Window (50/10s)')\n",
    "\n",
    "plt.xlabel('Request Rate (req/s)')\n",
    "plt.ylabel('Accepted Rate (req/s)')\n",
    "plt.title('Rate Limiting Algorithm Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nRate Limiting Effectiveness:\")\n",
    "for i, rate in enumerate(rates):\n",
    "    tb_eff = results['token_bucket'][i] / results['no_limit'][i]\n",
    "    sw_eff = results['sliding_window'][i] / results['no_limit'][i]\n",
    "    print(f\"  {rate} req/s: Token Bucket {tb_eff:.1%}, Sliding Window {sw_eff:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Rate limiting is essential for LLM serving systems:\n",
    "\n",
    "1. **Token Bucket**: Good for handling bursts while maintaining average rate\n",
    "2. **Sliding Window**: Provides precise rate control over time windows\n",
    "3. **Multi-Dimensional**: Controls multiple resource types (requests, tokens, cost)\n",
    "4. **Fair Queuing**: Ensures fair resource allocation across tenants\n",
    "\n",
    "Choose the right algorithm based on your specific requirements for burst handling, precision, and fairness."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
