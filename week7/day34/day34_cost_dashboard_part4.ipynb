{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 34: Cost Dashboard - Part 4\n",
    "\n",
    "Building a comprehensive cost/performance dashboard for LLM serving systems.\n",
    "\n",
    "## Overview\n",
    "1. Cost metrics collection\n",
    "2. Performance tracking\n",
    "3. Dashboard visualization\n",
    "4. Optimization recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict, deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cost Metrics Collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CostMetricsCollector:\n",
    "    def __init__(self):\n",
    "        self.metrics = defaultdict(list)\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def record_request(self, tenant_id, tokens_input, tokens_output, \n",
    "                      processing_time, cost, cached=False):\n",
    "        \"\"\"Record metrics for a request.\"\"\"\n",
    "        timestamp = time.time()\n",
    "        \n",
    "        metric = {\n",
    "            'timestamp': timestamp,\n",
    "            'tenant_id': tenant_id,\n",
    "            'tokens_input': tokens_input,\n",
    "            'tokens_output': tokens_output,\n",
    "            'total_tokens': tokens_input + tokens_output,\n",
    "            'processing_time': processing_time,\n",
    "            'cost': cost,\n",
    "            'cached': cached,\n",
    "            'tokens_per_second': (tokens_input + tokens_output) / processing_time if processing_time > 0 else 0\n",
    "        }\n",
    "        \n",
    "        self.metrics['requests'].append(metric)\n",
    "    \n",
    "    def record_infrastructure(self, gpu_utilization, memory_usage, \n",
    "                            active_requests, queue_length):\n",
    "        \"\"\"Record infrastructure metrics.\"\"\"\n",
    "        timestamp = time.time()\n",
    "        \n",
    "        metric = {\n",
    "            'timestamp': timestamp,\n",
    "            'gpu_utilization': gpu_utilization,\n",
    "            'memory_usage': memory_usage,\n",
    "            'active_requests': active_requests,\n",
    "            'queue_length': queue_length\n",
    "        }\n",
    "        \n",
    "        self.metrics['infrastructure'].append(metric)\n",
    "    \n",
    "    def get_cost_summary(self, time_window_hours=1):\n",
    "        \"\"\"Get cost summary for the specified time window.\"\"\"\n",
    "        cutoff = time.time() - (time_window_hours * 3600)\n",
    "        recent_requests = [r for r in self.metrics['requests'] \n",
    "                          if r['timestamp'] >= cutoff]\n",
    "        \n",
    "        if not recent_requests:\n",
    "            return {}\n",
    "        \n",
    "        total_cost = sum(r['cost'] for r in recent_requests)\n",
    "        total_tokens = sum(r['total_tokens'] for r in recent_requests)\n",
    "        total_requests = len(recent_requests)\n",
    "        cached_requests = sum(1 for r in recent_requests if r['cached'])\n",
    "        \n",
    "        avg_processing_time = np.mean([r['processing_time'] for r in recent_requests])\n",
    "        avg_tokens_per_second = np.mean([r['tokens_per_second'] for r in recent_requests])\n",
    "        \n",
    "        return {\n",
    "            'total_cost': total_cost,\n",
    "            'total_tokens': total_tokens,\n",
    "            'total_requests': total_requests,\n",
    "            'cached_requests': cached_requests,\n",
    "            'cache_hit_rate': cached_requests / total_requests if total_requests > 0 else 0,\n",
    "            'avg_cost_per_request': total_cost / total_requests if total_requests > 0 else 0,\n",
    "            'avg_cost_per_token': total_cost / total_tokens if total_tokens > 0 else 0,\n",
    "            'avg_processing_time': avg_processing_time,\n",
    "            'avg_tokens_per_second': avg_tokens_per_second,\n",
    "            'requests_per_hour': total_requests / time_window_hours\n",
    "        }\n",
    "\n",
    "# Initialize collector\n",
    "collector = CostMetricsCollector()\n",
    "\n",
    "# Simulate some data\n",
    "tenants = ['basic_tenant', 'premium_tenant', 'enterprise_tenant']\n",
    "costs_per_token = {'basic_tenant': 0.002, 'premium_tenant': 0.001, 'enterprise_tenant': 0.0008}\n",
    "\n",
    "print(\"Simulating request data...\")\n",
    "for i in range(100):\n",
    "    tenant = np.random.choice(tenants)\n",
    "    tokens_input = np.random.randint(50, 300)\n",
    "    tokens_output = np.random.randint(20, 200)\n",
    "    processing_time = (tokens_input + tokens_output) * 0.01 + np.random.normal(0, 0.1)\n",
    "    processing_time = max(0.01, processing_time)\n",
    "    \n",
    "    cached = np.random.random() < 0.2  # 20% cache hit rate\n",
    "    cost = 0 if cached else (tokens_input + tokens_output) * costs_per_token[tenant]\n",
    "    \n",
    "    collector.record_request(tenant, tokens_input, tokens_output, \n",
    "                           processing_time, cost, cached)\n",
    "    \n",
    "    # Simulate infrastructure metrics\n",
    "    if i % 10 == 0:\n",
    "        gpu_util = np.random.uniform(60, 95)\n",
    "        memory_usage = np.random.uniform(70, 90)\n",
    "        active_reqs = np.random.randint(5, 20)\n",
    "        queue_len = np.random.randint(0, 10)\n",
    "        \n",
    "        collector.record_infrastructure(gpu_util, memory_usage, active_reqs, queue_len)\n",
    "\n",
    "print(\"Data simulation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dashboard Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cost_dashboard(collector):\n",
    "    \"\"\"Create comprehensive cost dashboard.\"\"\"\n",
    "    \n",
    "    # Get summary metrics\n",
    "    summary = collector.get_cost_summary()\n",
    "    \n",
    "    # Prepare data\n",
    "    requests_df = pd.DataFrame(collector.metrics['requests'])\n",
    "    infra_df = pd.DataFrame(collector.metrics['infrastructure'])\n",
    "    \n",
    "    # Create dashboard\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # 1. Cost over time\n",
    "    ax1 = plt.subplot(3, 3, 1)\n",
    "    requests_df['cumulative_cost'] = requests_df['cost'].cumsum()\n",
    "    ax1.plot(requests_df.index, requests_df['cumulative_cost'])\n",
    "    ax1.set_title('Cumulative Cost Over Time')\n",
    "    ax1.set_ylabel('Cost ($)')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Cost by tenant\n",
    "    ax2 = plt.subplot(3, 3, 2)\n",
    "    cost_by_tenant = requests_df.groupby('tenant_id')['cost'].sum()\n",
    "    ax2.bar(cost_by_tenant.index, cost_by_tenant.values)\n",
    "    ax2.set_title('Cost by Tenant')\n",
    "    ax2.set_ylabel('Total Cost ($)')\n",
    "    plt.setp(ax2.get_xticklabels(), rotation=45)\n",
    "    \n",
    "    # 3. Cache hit rate impact\n",
    "    ax3 = plt.subplot(3, 3, 3)\n",
    "    cached_costs = requests_df[requests_df['cached']]['cost'].sum()\n",
    "    uncached_costs = requests_df[~requests_df['cached']]['cost'].sum()\n",
    "    ax3.pie([cached_costs, uncached_costs], labels=['Cached', 'Uncached'], autopct='%1.1f%%')\n",
    "    ax3.set_title('Cost Distribution: Cached vs Uncached')\n",
    "    \n",
    "    # 4. Tokens per second distribution\n",
    "    ax4 = plt.subplot(3, 3, 4)\n",
    "    ax4.hist(requests_df['tokens_per_second'], bins=20, alpha=0.7)\n",
    "    ax4.set_title('Tokens per Second Distribution')\n",
    "    ax4.set_xlabel('Tokens/Second')\n",
    "    ax4.set_ylabel('Frequency')\n",
    "    \n",
    "    # 5. Processing time vs tokens\n",
    "    ax5 = plt.subplot(3, 3, 5)\n",
    "    ax5.scatter(requests_df['total_tokens'], requests_df['processing_time'], alpha=0.6)\n",
    "    ax5.set_title('Processing Time vs Total Tokens')\n",
    "    ax5.set_xlabel('Total Tokens')\n",
    "    ax5.set_ylabel('Processing Time (s)')\n",
    "    \n",
    "    # 6. GPU utilization over time\n",
    "    ax6 = plt.subplot(3, 3, 6)\n",
    "    if not infra_df.empty:\n",
    "        ax6.plot(infra_df.index, infra_df['gpu_utilization'])\n",
    "        ax6.set_title('GPU Utilization Over Time')\n",
    "        ax6.set_ylabel('GPU Utilization (%)')\n",
    "        ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 7. Cost efficiency by tenant\n",
    "    ax7 = plt.subplot(3, 3, 7)\n",
    "    efficiency = requests_df.groupby('tenant_id').apply(\n",
    "        lambda x: x['total_tokens'].sum() / x['cost'].sum() if x['cost'].sum() > 0 else 0\n",
    "    )\n",
    "    ax7.bar(efficiency.index, efficiency.values)\n",
    "    ax7.set_title('Cost Efficiency (Tokens per Dollar)')\n",
    "    ax7.set_ylabel('Tokens/$')\n",
    "    plt.setp(ax7.get_xticklabels(), rotation=45)\n",
    "    \n",
    "    # 8. Request volume over time (hourly)\n",
    "    ax8 = plt.subplot(3, 3, 8)\n",
    "    requests_df['hour'] = (requests_df.index // 10).astype(int)  # Group by 10s for demo\n",
    "    hourly_requests = requests_df.groupby('hour').size()\n",
    "    ax8.bar(hourly_requests.index, hourly_requests.values)\n",
    "    ax8.set_title('Request Volume Over Time')\n",
    "    ax8.set_ylabel('Requests')\n",
    "    \n",
    "    # 9. Key metrics summary\n",
    "    ax9 = plt.subplot(3, 3, 9)\n",
    "    ax9.axis('off')\n",
    "    \n",
    "    metrics_text = f\"\"\"\n",
    "    KEY METRICS\n",
    "    \n",
    "    Total Cost: ${summary.get('total_cost', 0):.3f}\n",
    "    Total Requests: {summary.get('total_requests', 0)}\n",
    "    Total Tokens: {summary.get('total_tokens', 0):,}\n",
    "    \n",
    "    Cache Hit Rate: {summary.get('cache_hit_rate', 0):.1%}\n",
    "    Avg Cost/Request: ${summary.get('avg_cost_per_request', 0):.4f}\n",
    "    Avg Cost/Token: ${summary.get('avg_cost_per_token', 0):.5f}\n",
    "    \n",
    "    Avg Processing Time: {summary.get('avg_processing_time', 0):.3f}s\n",
    "    Avg Tokens/Second: {summary.get('avg_tokens_per_second', 0):.1f}\n",
    "    Requests/Hour: {summary.get('requests_per_hour', 0):.1f}\n",
    "    \"\"\"\n",
    "    \n",
    "    ax9.text(0.1, 0.9, metrics_text, transform=ax9.transAxes, \n",
    "             fontsize=10, verticalalignment='top', fontfamily='monospace')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Create dashboard\n",
    "summary = create_cost_dashboard(collector)\n",
    "print(\"\\nDashboard created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optimization Recommendations Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizationEngine:\n",
    "    def __init__(self, collector):\n",
    "        self.collector = collector\n",
    "    \n",
    "    def analyze_and_recommend(self):\n",
    "        \"\"\"Analyze metrics and provide optimization recommendations.\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        # Get recent data\n",
    "        summary = self.collector.get_cost_summary()\n",
    "        requests_df = pd.DataFrame(self.collector.metrics['requests'])\n",
    "        infra_df = pd.DataFrame(self.collector.metrics['infrastructure'])\n",
    "        \n",
    "        # 1. Cache optimization\n",
    "        cache_hit_rate = summary.get('cache_hit_rate', 0)\n",
    "        if cache_hit_rate < 0.3:\n",
    "            potential_savings = summary.get('total_cost', 0) * (0.3 - cache_hit_rate)\n",
    "            recommendations.append({\n",
    "                'type': 'Cache Optimization',\n",
    "                'priority': 'High',\n",
    "                'description': f'Cache hit rate is {cache_hit_rate:.1%}. Improving to 30% could save ${potential_savings:.3f}',\n",
    "                'action': 'Implement semantic caching or increase cache size'\n",
    "            })\n",
    "        \n",
    "        # 2. Processing efficiency\n",
    "        avg_tokens_per_sec = summary.get('avg_tokens_per_second', 0)\n",
    "        if avg_tokens_per_sec < 50:\n",
    "            recommendations.append({\n",
    "                'type': 'Processing Efficiency',\n",
    "                'priority': 'Medium',\n",
    "                'description': f'Average throughput is {avg_tokens_per_sec:.1f} tokens/sec, which is below optimal',\n",
    "                'action': 'Consider model quantization or better batching strategies'\n",
    "            })\n",
    "        \n",
    "        # 3. GPU utilization\n",
    "        if not infra_df.empty:\n",
    "            avg_gpu_util = infra_df['gpu_utilization'].mean()\n",
    "            if avg_gpu_util < 70:\n",
    "                recommendations.append({\n",
    "                    'type': 'Resource Utilization',\n",
    "                    'priority': 'Medium',\n",
    "                    'description': f'GPU utilization is {avg_gpu_util:.1f}%, indicating underutilization',\n",
    "                    'action': 'Increase batch sizes or implement auto-scaling'\n",
    "                })\n",
    "        \n",
    "        # 4. Cost per token analysis\n",
    "        cost_per_token = summary.get('avg_cost_per_token', 0)\n",
    "        if cost_per_token > 0.002:\n",
    "            recommendations.append({\n",
    "                'type': 'Cost Optimization',\n",
    "                'priority': 'High',\n",
    "                'description': f'Cost per token is ${cost_per_token:.5f}, which is above industry average',\n",
    "                'action': 'Review pricing tiers or negotiate better rates with providers'\n",
    "            })\n",
    "        \n",
    "        # 5. Tenant efficiency analysis\n",
    "        if not requests_df.empty:\n",
    "            tenant_efficiency = requests_df.groupby('tenant_id').apply(\n",
    "                lambda x: x['total_tokens'].sum() / x['cost'].sum() if x['cost'].sum() > 0 else float('inf')\n",
    "            )\n",
    "            \n",
    "            inefficient_tenants = tenant_efficiency[tenant_efficiency < 1000].index.tolist()\n",
    "            if inefficient_tenants:\n",
    "                recommendations.append({\n",
    "                    'type': 'Tenant Optimization',\n",
    "                    'priority': 'Low',\n",
    "                    'description': f'Tenants {inefficient_tenants} have low cost efficiency',\n",
    "                    'action': 'Review usage patterns and consider tier adjustments'\n",
    "                })\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def estimate_savings(self, recommendations):\n",
    "        \"\"\"Estimate potential cost savings from recommendations.\"\"\"\n",
    "        summary = self.collector.get_cost_summary()\n",
    "        total_cost = summary.get('total_cost', 0)\n",
    "        \n",
    "        estimated_savings = 0\n",
    "        \n",
    "        for rec in recommendations:\n",
    "            if rec['type'] == 'Cache Optimization':\n",
    "                estimated_savings += total_cost * 0.2  # 20% savings from better caching\n",
    "            elif rec['type'] == 'Processing Efficiency':\n",
    "                estimated_savings += total_cost * 0.15  # 15% savings from efficiency\n",
    "            elif rec['type'] == 'Resource Utilization':\n",
    "                estimated_savings += total_cost * 0.1   # 10% savings from better utilization\n",
    "            elif rec['type'] == 'Cost Optimization':\n",
    "                estimated_savings += total_cost * 0.25  # 25% savings from cost optimization\n",
    "        \n",
    "        return min(estimated_savings, total_cost * 0.5)  # Cap at 50% savings\n",
    "\n",
    "# Generate recommendations\n",
    "optimizer = OptimizationEngine(collector)\n",
    "recommendations = optimizer.analyze_and_recommend()\n",
    "estimated_savings = optimizer.estimate_savings(recommendations)\n",
    "\n",
    "print(\"\\n=== OPTIMIZATION RECOMMENDATIONS ===\")\n",
    "print(f\"Potential Monthly Savings: ${estimated_savings * 30:.2f}\")\n",
    "print(\"\\nRecommendations:\")\n",
    "\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"\\n{i}. {rec['type']} (Priority: {rec['priority']})\")\n",
    "    print(f\"   Issue: {rec['description']}\")\n",
    "    print(f\"   Action: {rec['action']}\")\n",
    "\n",
    "if not recommendations:\n",
    "    print(\"\\nNo optimization opportunities identified. System is running efficiently!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "A comprehensive cost dashboard provides:\n",
    "\n",
    "1. **Real-time Monitoring**: Track costs, performance, and resource utilization\n",
    "2. **Trend Analysis**: Identify patterns and anomalies in usage\n",
    "3. **Optimization Insights**: Automated recommendations for cost reduction\n",
    "4. **ROI Tracking**: Measure impact of optimization efforts\n",
    "\n",
    "This dashboard enables data-driven decisions for cost optimization in LLM serving systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
