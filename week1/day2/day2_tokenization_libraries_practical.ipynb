{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2: Advanced Tokenization with tiktoken and tokenizers - Practical Exercises\n",
    "\n",
    "This notebook contains hands-on exercises and implementations for Day 2 of the LLM learning journey.\n",
    "\n",
    "## Learning Objectives\n",
    "- Implement tokenization using tiktoken and Hugging Face tokenizers\n",
    "- Compare different tokenization libraries and their performance\n",
    "- Analyze vocabulary size vs sequence length trade-offs\n",
    "- Create custom domain-specific tokenizers\n",
    "- Benchmark tokenizer performance\n",
    "\n",
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install tiktoken tokenizers transformers matplotlib seaborn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE, WordPiece\n",
    "from tokenizers.trainers import BpeTrainer, WordPieceTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from tokenizers.normalizers import Sequence, NFD, Lowercase, StripAccents\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. tiktoken: OpenAI's Fast Tokenizer\n",
    "\n",
    "Let's start by exploring tiktoken and its different encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get different tiktoken encodings\n",
    "gpt2_enc = tiktoken.get_encoding(\"gpt2\")\n",
    "gpt4_enc = tiktoken.get_encoding(\"cl100k_base\")  # GPT-4\n",
    "codex_enc = tiktoken.get_encoding(\"p50k_base\")   # Code models\n",
    "\n",
    "# Test text\n",
    "text = \"Hello, world! This is advanced tokenization with tiktoken. Let's see how it handles different types of text: code_variable, Ã©mojis ðŸš€, and numbers 12345.\"\n",
    "\n",
    "print(f\"Original text: {text}\")\n",
    "print(f\"Text length: {len(text)} characters\\n\")\n",
    "\n",
    "# Compare different encodings\n",
    "encodings = {\n",
    "    'GPT-2': gpt2_enc,\n",
    "    'GPT-4': gpt4_enc,\n",
    "    'Codex': codex_enc\n",
    "}\n",
    "\n",
    "for name, enc in encodings.items():\n",
    "    tokens = enc.encode(text)\n",
    "    decoded = enc.decode(tokens)\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Tokens: {len(tokens)}\")\n",
    "    print(f\"  Vocab size: {enc.n_vocab:,}\")\n",
    "    print(f\"  First 10 tokens: {tokens[:10]}\")\n",
    "    print(f\"  Decoded tokens: {[enc.decode([t]) for t in tokens[:10]]}\")\n",
    "    print(f\"  Perfect reconstruction: {decoded == text}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
